# Hub Design (Cloud Intelligence Architecture)

このドキュメントは、GCP Cloud Run上で動作する **Hub** コンポーネント（Cloud Intelligence Hub）の詳細設計を記述する。

## 1. 責務とコア概念

Hub層の主な責務は以下の通り：
1.  **プロファイリングと知能の提供**: 検索時のリランキング（最適な関数の選別）や、コードの品質評価を行うための「高品質なプロンプト」を生成し、Edgeに提供する。
2.  **IP（知的財産）の秘匿**: 最も価値のある「どのようなプロンプトでAIに評価させるか」「品質をどう測るか」というロジックをクラウド側に置き、悪意のある利用者のリバースエンジニアリングから保護する。
3.  **完全ステートレス**: DBを持たず、リクエストを受け取ってレスポンスを返すだけの純粋な関数として存在する。

## 2. コンポーネント詳細

### 2.1 FastAPI Server (`backend/hub/app.py` etc.)
*   **フレームワーク**: Python 3.12-slim 上の FastAPI。
*   **ホスティング**: GCP Cloud Run (Serverless)。
*   **特徴**: ステートフルなデータベース接続を持たない。これにより、トラフィックの増大に対して無限に水平スケールが可能であり、アクセスがない時はインスタンス数をゼロにしてコストを完全に削減できる。

### 2.2 Intelligence Router (`backend/hub/router.py`)
曖昧な自然言語要求に対し、Edgeから送られてきた複数候補（Candidates）の中から、どれが最適かを選別（Reranking）するノウハウをカプセル化している。

*   **Reverse Intelligenceフローにおける役割**: 
    1. 候補群の情報を受け取る。
    2. LLM向けの「指示書（Prompt）」を生成して返す。
    3. Edgeがそのプロンプトを用いて自前のAPIキーで推論を行う。
    4. 推論結果（llm_output）を再度Hubが受け取り、適切にパースして承認（Finalize）する。
*   この設計により、Hubはユーザーのトラフィックコストや推論APIコスト（Gemini等のトークン代）を一切負担せず、純粋に「司令」だけを下す存在になれる。

### 2.3 Quality Gate
*   **役割**: サブミット（保存）されようとしている関数の品質を静的に評価する。
*   **実装**: RuffなどのLinterルール、AST検査、セキュリティシグネチャのチェック等が含まれる。
*   **Draft Firstとの関係**: Edge側では構文エラーのあるコードでも下書き（Draft）として保存できるが、HubにPublishされる前にこのQuality Gateによってスコアリングされ、一定水準を満たさないコードはグローバルリポジトリのインデックスから除外（あるいは警告タグ付与）される。

## 3. なぜクラウド側の処理を軽くしたのか？（Thin-Cloud原則）

1.  **コスト最小化**: Cloud Runの計算リソース消費時間を極限まで短くし（プロンプトを文字列生成して返すだけなら数ミリ秒で終わる）、従量課金を抑える。
2.  **BYOK (Bring Your Own Key) の実現**: SaaS運営側の推論APIキーを使わず、ユーザー自身のキーを使わせるため、最も重い処理（LLMコール）をあえてEdgeに押し付けている。
3.  **ステートレスの担保**: 以前のバージョンではベクトルDBへの接続を試みていたが、状態を持つことはアンチパターンであるため修正された。

## 4. 配布ポリシー
このHubのコードパス（`backend/hub/` などの知能の中核）は、公開リポジトリやnpmパッケージには **含まれない**。これこそが本システムのコアの価値（IP）であるためだ。
